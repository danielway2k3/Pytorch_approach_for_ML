{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn.datasets import make_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "        X: input tensor\n",
    "        lr: learning rate\n",
    "        epochs: number of times the model iterates over complete dataset\n",
    "        weights: params learned during training\n",
    "        bias: param learned during training\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, lr=1e-3, epochs=1000):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.m, self.n = X.shape\n",
    "        self.bias = 0\n",
    "        self.weights = torch.zeros((self.n, 1), dtype=torch.double)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "            z: latent variable presents (wx + b)\n",
    "            return: the real value between 0 and 1 representing probability score\n",
    "        \"\"\"\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "    def loss(self, y_hat):\n",
    "        \"\"\"\n",
    "            y_hat: predicted value\n",
    "            return: loss value\n",
    "        \"\"\"\n",
    "        return -(1 / self.m) * torch.sum(\n",
    "            self.y * torch.log(y_hat) + (1 - self.y) * torch.log(1 - y_hat)\n",
    "        )\n",
    "\n",
    "    def gradient(self, y_pred):\n",
    "        \"\"\"\n",
    "            y_pred: predicted value\n",
    "            return: gradient of the loss function\n",
    "        \"\"\"\n",
    "        dw = 1/self.m * torch.mm(self.X.T, (y_pred - self.y))\n",
    "        db = 1/self.m * torch.sum(y_pred - self.y)\n",
    "\n",
    "        return dw, db\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "            X: input tensor\n",
    "            return: trained model\n",
    "        \"\"\"\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            y_pred = self.sigmoid(torch.mm(X, self.weights) + self.bias)\n",
    "            cost = self.loss(y_pred)\n",
    "            dw, db = self.gradient(y_pred)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"-\"*60)\n",
    "                print(f\"Epoch {epoch}/{self.epochs} | Loss: {cost}\")\n",
    "            \n",
    "        return self.weights, self.bias\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X: input tensor\n",
    "            y_predict_label: Converts float value to int/bool true(1) or false(0)\n",
    "            return: predicted value\n",
    "        \"\"\"\n",
    "        y_predict = self.sigmoid(torch.mm(X, self.weights) + self.bias)\n",
    "        y_predict_labels = y_predict > 0.5\n",
    "\n",
    "        return y_predict_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "X, y = make_blobs(n_samples=1000, centers=2)\n",
    "X = torch.tensor(X, dtype=torch.double)\n",
    "y = torch.tensor(y, dtype=torch.double).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "        y_true: true value\n",
    "        y_pred: predicted value\n",
    "        return: accuracy score\n",
    "    \"\"\"\n",
    "    return torch.sum(y_true == y_pred) / len(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 100/1000 | Loss: 0.29704029675529564\n",
      "------------------------------------------------------------\n",
      "Epoch 200/1000 | Loss: 0.1871177656042021\n",
      "------------------------------------------------------------\n",
      "Epoch 300/1000 | Loss: 0.13806849053486264\n",
      "------------------------------------------------------------\n",
      "Epoch 400/1000 | Loss: 0.11025305967853233\n",
      "------------------------------------------------------------\n",
      "Epoch 500/1000 | Loss: 0.0922584756741377\n",
      "------------------------------------------------------------\n",
      "Epoch 600/1000 | Loss: 0.07961681269239149\n",
      "------------------------------------------------------------\n",
      "Epoch 700/1000 | Loss: 0.07022124613817651\n",
      "------------------------------------------------------------\n",
      "Epoch 800/1000 | Loss: 0.06294699212526063\n",
      "------------------------------------------------------------\n",
      "Epoch 900/1000 | Loss: 0.05713783413495402\n",
      "------------------------------------------------------------\n",
      "Epoch 1000/1000 | Loss: 0.05238455109692046\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(X, y)\n",
    "w, b = model.fit(X)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "accuracy = accuracy(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
